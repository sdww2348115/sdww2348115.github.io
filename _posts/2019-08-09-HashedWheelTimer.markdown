---
layout: post
title:  "HashedWheelTimer原理分析"
date:   2019-08-09 23:30:00 +0800
categories: java jdk netty scheduler datastructure
permalink: /datastructure/HashedWheelTimer
description: HashedWheelTimer原理分析
---

## 背景

比如IM等有许多长连接的情况时，需要服务器端一一维护客户端状态。当客户端的数量很大时，可能需要维护大量timer，或者进行低效的扫描。

`通常实现方式`

轮询扫描
1. 使用一个map来记录每一个客户端最后一次与服务器端的通信时间
2. 当客户端有数据传输或者心跳报文时，实时更新此Map的值
3. 启动一个定时任务，以固定时间间隔对该Map进行轮询扫描：当前时间 - 最后一次通信时间 > 预设超时时间时， client将被标记为超时，被执行超时逻辑。
缺点：当数据较多时，对整个Map进行全量扫描的时间较长，两次扫描之间的时间也会较长，判断连接超时的误差范围较大。

timer跟踪
1. 客户端与服务器建立连接后，启动一个watch线程对该链路进行跟踪
2. 客户端有数据传输或者心跳报文时，实时更新连接的最后通信时间属性
3. watch线程定时扫描：当前时间 - 最后一次通信时间 > 预设超时时间时，client将被标记为超时，watch线程将被标记为超时，被执行超时逻辑
缺点：启动的线程过多，当连接数较大时，watch线程的开销也会非常大，服务器吞吐降低。

## WheelTimer核心算法
采用分而治之的思想对轮询扫描法进行优化：将Mao中存放的所有客户端通信记录分散到多个数据结构中，避免了对整个Map进行全量扫描，同时也使得触发的时间间隔大大减小，提高了整体监控的效率以及敏感度。

借助时钟与Hash函数的思想对定时任务进行划分：

1. 以任务的触发时间作为hash的key，将所有定时任务分配至若干slot中
2. 借助钟表的思想，将slot数组首尾相连，在每个slot代表的时间间隔一定的情况下，遍历整个slot数组的时间固定为n * tickDuration。此时采用slot下标以及所需遍历轮数即可`大致`定位任务的触发时间。

![wheelTimer](../resources/img/wheelTimer.png)

如上图所示，假设每两个slot之间的触发时间为1s,那么遍历整个slot数组的时间为1 * 8 = 8s，一个定时任务将要在60s后触发，60 / 8 = 7 ... 4 。那么该定时任务应存放在下标为4的slot中，同时标记其剩余圈数为4。


